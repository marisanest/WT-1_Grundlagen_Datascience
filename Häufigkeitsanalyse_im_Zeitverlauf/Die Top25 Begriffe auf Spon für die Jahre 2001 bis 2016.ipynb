{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://stackoverflow.com/questions/37508659/group-by-and-count-distinct-words-in-pandas-dataframe\n",
    "\n",
    "http://stackoverflow.com/questions/14262433/large-data-work-flows-using-pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "insgesamt 855M\r\n",
      "9835269 drwxr-xr-x 2 sebsch sebsch 4,0K 21. Dez 20:03 .\r\n",
      "9835151 drwxr-xr-x 6 sebsch sebsch 4,0K 27. Dez 22:18 ..\r\n",
      "9835815 -rw-r--r-- 1 sebsch sebsch 855M 21. Dez 21:02 SPON_complete\r\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "!ls -liLah ../../share/Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rohdaten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# generate the raw_data from CSV\n",
    "raw_data = pd.read_csv(\"../../share/Data/SPON_complete\", delimiter=\",\", skipinitialspace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stopwörter\n",
    "\n",
    "\n",
    "Verwendung der Stopwörter von [hier](https://github.com/solariz/german_stopwords). Diese liegen in einer MIT Lizenz vor.\n",
    "\n",
    "Diese Liste wird Dynamisch erweitert.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Stopwords are downloaded and defined here\n",
    "try:\n",
    "    with open(\"../german_stopwords_full.txt\") as f:\n",
    "        STOPWORDS = [line.strip() for line in f if not line.startswith(\";\")]\n",
    "except FileNotFoundError:\n",
    "    !wget https://raw.githubusercontent.com/solariz/german_stopwords/master/german_stopwords_full.txt\n",
    "    with open(\"../german_stopwords_full.txt\") as f:\n",
    "        STOPWORDS = [line.strip() for line in f if not line.startswith(\";\")] \n",
    "    \n",
    "dynamic_stopwords = [\"dass\", \"\", \" \", \"worden\", \"jahren\", \"jahre\", \"jahr\", \n",
    "                     \"heißt\", \"heißen\", \"müsse\", \"prozent\"]\n",
    "\n",
    "STOPWORDS += dynamic_stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aufbereiten der Rohdaten\n",
    "\n",
    "Die Artikel werden von Sonderzeichen und den Stopwörtern befreit.\n",
    "\n",
    "\n",
    "**Problem**: \n",
    "\n",
    "- Bei jeder Änderung der wachsenden Stopwörterliste muss dieser Schritt neu ausgeführt werden.\n",
    "    - $\\to$ Von Konkatenierung mit der dynamischen Liste absehen und diese später beim zählen bereinigen.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# Aufbereitung der Daten zur späteren Bearbeitung\n",
    "\n",
    "## TODO: nicht mit DF sondern als Text bearbeiten -- Zeit- und Memkritisch\n",
    "data = raw_data\n",
    "if False:\n",
    "    # Cleaning the strings to be only alphanumeric\n",
    "    data['article'] = data['article'].map(lambda x: re.sub(r'\\W+', '', str(x), re.UNICODE))\n",
    "    # Removing the stopwords\n",
    "    data['article'] = data['article'].map(lambda x: [item for item in x.split() if item not in STOPWORDS])\n",
    "\n",
    "    data.to_csv(\"./share/Data/SPON_complete_clean.csv\".format(word) , sep=',')\n",
    "\n",
    "    data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zählen\n",
    "\n",
    "Die Wörter werden gezählt und sortiert als Dataframe zurückgegeben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def count_words(source):\n",
    "    \"\"\" Counting the words of the column article of a given Dataframe.\n",
    "    \n",
    "    It is possible to define a word, so only this word will be counted.\n",
    "    \"\"\"\n",
    "    \n",
    "    #split column Message to new df, create Serie by stack\n",
    "    s = (source.article.str.split(expand=True).stack().str.lower()   )\n",
    "    #remove multiindex\n",
    "    s.index = s.index.droplevel(-1)\n",
    "    s.name= 'words'\n",
    "    #join Serie s to df source\n",
    "    df = (source.join(s))\n",
    "    \n",
    "    # Cleaning the strings to be only alphanumeric\n",
    "    df['words'] = df['words'].map(lambda x: re.sub(r'\\W+', '', str(x), re.U))\n",
    "    df = df[~df['words'].isin(\n",
    "            STOPWORDS)].groupby(\n",
    "            ['words']).size().reset_index(\n",
    "            name='count'\n",
    "    ).sort_values(by='count')\n",
    "        \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def wordcounter(source, word):\n",
    "    df = count_words(source)\n",
    "    return df[df['words'].str.contains(word)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This will generate a list of Strings, representating the months from .01.2001 to .12.2012\n",
    "datestrings = [\".{:02d}.20{:02d}\".format(m,y)  for y in range(1, 17) for m in range(1, 13) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "top25words_ofCategory = lambda m, c : count_words(\n",
    "    raw_data[ \n",
    "        (raw_data.day.str.contains(m, na=False)) & (raw_data.cats.str.contains(c, na=False) )] \n",
    "    ).nlargest(25, columns=['count', ]).set_index('words')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aufbereiten der Daten und schreiben in CSV-Dateien"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen = False\n",
    "\n",
    "if gen:\n",
    "    _ = [top25words_ofCategory('{}'.format(Y), \n",
    "                           'Politik').to_csv(\"../../share/DATA/politics_top25words_{}.csv\".format(Y)) \n",
    "     for Y in range(2001, 2017)]"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
